# -*- coding: utf-8 -*-
"""catboost_konservasi_lahan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eNjwPudPorT5_Wdnm7_Ua9Mbd2mxFOUg
"""

!pip install catboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, hamming_loss
from sklearn.preprocessing import MultiLabelBinarizer
import warnings
import os

warnings.filterwarnings('ignore')

# Dictionary untuk mapping label konservasi ke tanaman
label_to_tanaman = {
    "Agroforestry MPTS berevaporasi tinggi dan perakaran dalam": [
        "Alpukat", "Aren", "Asam Jawa", "Duku", "Durian", "Kecapi",
        "Kelapa", "Kemiri", "Mangga", "Sukun"
    ],
    "Agroforestry berevaporasi tinggi dan perakaran dalam": [],
    "Agroforestry kayu-kayuan atau MPTS": [
        "Duku", "Durian", "Kemiri", "Mangga", "Manggis"
    ],
    "Alley cropping MPTS berevaporasi tinggi dan perakaran dalam": [
        "Alpukat", "Aren", "Asam Jawa", "Duku", "Durian", "Kecapi",
        "Kelapa", "Kemiri", "Mangga", "Sukun"
    ],
    "Alley cropping kayu-kayuan atau MPTS": [
        "Duku", "Durian", "Kemiri", "Mangga", "Manggis"
    ],
    "Contouring": [],
    "Countouring NTFP": [
        "Cengkeh", "Damar", "Jahe", "Karet", "Rotan"
    ],
    "Countouring NTFP berevaporasi tinggi dan perakaran dalam": [
        "Cengkeh", "Damar", "Kapuk", "Karet", "Kenanga", "Pepaya", "Pisang"
    ],
    "Countouring kayu komersil bernilai tinggi atau NTFP": [
        "Cemara", "Damar", "Giam", "Jelutung", "Jongkong", "Kapur", "Kawui",
        "Kayu Batu", "Kayu Labu", "Kayu bulan", "Kenari", "Kepinis", "Keruing",
        "Kulim", "Lancat", "Mahang", "Malapari", "Medang", "Meranti", "Okea",
        "Pala", "Pasir-pasir", "Punak", "Puspa", "Rengas", "Saninten", "Sempur",
        "Sengon", "Sowang", "Suren", "Tembesu", "Tenggayun", "Terap",
        "Terentang Ayam", "Terentang putih", "Tusam", "Utap-utap", "Waru Gunung"
    ],
    "Cover crop": [],
    "Dam penahan": [],
    "Gully plug": [],
    "Instalasi pemanenan air hujan": [],
    "Intensifikasi pekarangan": [],
    "Lindungi air dari pencemaran": [],
    "Mulsa vertikal": [],
    "Pemeliharaan guludan dan saluran air": [],
    "Pemeliharaan teras dan saluran air": [],
    "Pemeliharan": [],
    "Penanaman NTFP": [
        "Cengkeh", "Damar", "Jahe", "Karet", "Rotan"
    ],
    "Penanaman NTFP berevaporasi tinggi dan perakaran dalam": [
        "Cengkeh", "Damar", "Kapuk", "Karet", "Kenanga", "Pepaya", "Pisang"
    ],
    "Penanaman kayu komersil bernilai tinggi": [
        "Cemara", "Damar", "Giam", "Jelutung", "Jongkong", "Kapur", "Kawui",
        "Kayu Batu", "Kayu Labu", "Kayu bulan", "Kenari", "Kepinis", "Keruing",
        "Kulim", "Lancat", "Mahang", "Malapari", "Medang", "Meranti", "Okea",
        "Pala", "Pasir-pasir", "Punak", "Puspa", "Rengas", "Saninten", "Sempur",
        "Sengon", "Sowang", "Suren", "Tembesu", "Tenggayun", "Terap",
        "Terentang Ayam", "Terentang putih", "Tusam", "Utap-utap", "Waru Gunung"
    ],
    "Penanaman kayu-kayuan berevaporasi tinggi dan perakaran dalam": [],
    "Penanaman pohon": [
        "Cempedak", "Duku", "Durian", "Jambu air", "Jambu biji", "Jengkol",
        "Kakao", "Kelengkeng", "Kemiri", "Mangga", "Manggis", "Melinjo",
        "Nangka", "Petai", "Sirsak"
    ],
    "Pengaturan drainase": [],
    "Pengkayaan MPTS berevaporasi tinggi dan perakaran dalam": [
        "Alpukat", "Aren", "Asam Jawa", "Duku", "Durian", "Kecapi", "Kelapa",
        "Kemiri", "Mangga", "Sukun"
    ],
    "Pengkayaan MPTS penyimpan air": [
        "Duku", "Durian", "Kemiri", "Mangga", "Manggis"
    ],
    "Pengkayaan NTFP atau kayu komersil bernilai tinggi": [
        "Cengkeh", "Damar", "Jahe", "Karet", "Rotan"
    ],
    "Pengkayaan NTFP berevaporasi tinggi dan perakaran dalam": [
        "Cengkeh", "Damar", "Kapuk", "Karet", "Kenanga", "Pepaya", "Pisang"
    ],
    "Pengkayaan NTFP berevaporsi tinggi dan perakaran dalam": [
        "Cengkeh", "Damar", "Jahe", "Karet", "Rotan"
    ],
    "Pengkayaan kayu komersil bernilai tinggi": [
        "Cemara", "Damar", "Giam", "Jelutung", "Jongkong", "Kapur", "Kawui",
        "Kayu Batu", "Kayu Labu", "Kayu bulan", "Kenari", "Kepinis", "Keruing",
        "Kulim", "Lancat", "Mahang", "Malapari", "Medang", "Meranti", "Okea",
        "Pala", "Pasir-pasir", "Punak", "Puspa", "Rengas", "Saninten", "Sempur",
        "Sengon", "Sowang", "Suren", "Tembesu", "Tenggayun", "Terap",
        "Terentang Ayam", "Terentang putih", "Tusam", "Utap-utap", "Waru Gunung"
    ],
    "Pengkayaan tanaman berevaporasi tinggi dan perakaran dalam": [
        "Akasia", "Alpukat", "Aren", "Asam Jawa", "Beringin", "Cengkeh", "Damar",
        "Duku", "Durian", "Eukaliptus", "Kapuk", "Karet", "Kecapi", "Kelapa",
        "Kelor", "Kemiri", "Kenanga", "Mangga", "Sukun", "Zaitun"
    ],
    "Pengkayaan tanaman penyimpan air": [],
    "Penguat teras": [],
    "Resapan air": [],
    "Rorak": [],
    "Saluran pembuangan air": [],
    "Teras bangku": []
}

# Function to preprocess data and handle missing values properly
def preprocess_data_for_catboost(df, categorical_cols, missing_value_placeholder="UNKNOWN"):
    """
    Preprocess data untuk CatBoost dengan handling missing values yang proper.

    Parameters:
    - df: DataFrame
    - categorical_cols: list of categorical column names
    - missing_value_placeholder: string untuk replace missing values

    Returns:
    - processed DataFrame
    """
    df_processed = df.copy()

    # Replace NaN values in categorical columns with string placeholder
    for col in categorical_cols:
        if col in df_processed.columns:
            df_processed[col] = df_processed[col].fillna(missing_value_placeholder)
            # Convert to string to be sure
            df_processed[col] = df_processed[col].astype(str)

    # Handle numerical columns - CatBoost can handle NaN in numerical features
    numerical_cols = [col for col in df_processed.columns if col not in categorical_cols]
    # No need to fill NaN in numerical columns as CatBoost handles them naturally

    return df_processed


df = pd.read_excel("/content/EP_19mei2024_dissolved.xlsx")
column_selected = ["FungsiKaw", "chbulan", "Lereng", "Solumtnh", "JnsLahan", "LC2024", "ErosiPot", "TBE", "Rekomendasi_Konservasi"]
df = df[column_selected]

# Data Preprocessing
df['Rekomendasi_List'] = df['Rekomendasi_Konservasi'].apply(lambda x: [item.strip() for item in x.split(', ')])
mlb = MultiLabelBinarizer()
y_encoded = mlb.fit_transform(df['Rekomendasi_List'])
y_df = pd.DataFrame(y_encoded, columns=mlb.classes_)

X = df.drop(['Rekomendasi_Konservasi', 'Rekomendasi_List'], axis=1)
y = y_df

# Identify categorical features
categorical_features_names = [col for col in X.columns if X[col].dtype == 'object']
print(f"Categorical features: {categorical_features_names}")

# Preprocess data for CatBoost
X_processed = preprocess_data_for_catboost(X, categorical_features_names)

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y.sum(axis=1))

# 2. Training Model
print("--- Training a Single Multi-label CatBoost Model ---")

train_pool = Pool(
    data=X_train,
    label=y_train,
    cat_features=categorical_features_names
)

eval_pool = Pool(
    data=X_test,
    label=y_test,
    cat_features=categorical_features_names
)

multi_label_model = CatBoostClassifier(
    iterations=2000,
    learning_rate=0.05,
    depth=8,
    loss_function='MultiLogloss',
    eval_metric='MultiLogloss',
    random_seed=42,
    verbose=200,
    early_stopping_rounds=200,
    task_type='GPU',
)

print("Starting model fitting...")
multi_label_model.fit(train_pool, eval_set=eval_pool)
print("\n--- Model Training Finished ---")

# 3. Evaluasi Model
print("\n--- Multi-label Evaluation (Test Set) ---")
y_pred_proba = multi_label_model.predict_proba(X_test)
prediction_threshold = 0.5
y_pred_binary = (y_pred_proba > prediction_threshold).astype(int)

print("Classification Report:")
print(classification_report(y_test, y_pred_binary, target_names=mlb.classes_, zero_division=0))

macro_f1 = f1_score(y_test, y_pred_binary, average='macro', zero_division=0)
micro_f1 = f1_score(y_test, y_pred_binary, average='micro', zero_division=0)
hamming_loss_score = hamming_loss(y_test, y_pred_binary)

print(f"\n--- Overall Metrics ---")
print(f"Macro F1-score: {macro_f1:.4f}")
print(f"Micro F1-score: {micro_f1:.4f}")
print(f"Hamming Loss: {hamming_loss_score:.4f}")

# 4. Visualisasi Feature Importance
print("\n--- Plotting Feature Importance ---")
feature_importance = multi_label_model.get_feature_importance()
importance_df = pd.DataFrame({
    'feature': X_processed.columns,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

plt.figure(figsize=(12, 8))
sns.barplot(x='importance', y='feature', data=importance_df)
plt.title('Overall Feature Importance for Multi-label Model')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.tight_layout()
plt.show()

# 5. Fungsi Prediksi dengan Rekomendasi Tanaman (Fixed untuk handle missing values)
def predict_with_plant_recommendations(new_data, model, mlb_classes, label_to_tanaman_dict,
                                     categorical_cols, threshold=0.5, missing_placeholder="UNKNOWN"):
    """
    Fungsi prediksi yang menambahkan rekomendasi tanaman berdasarkan hasil klasifikasi.
    Dapat menangani missing values dengan preprocessing yang proper.
    """
    # Preprocess new data same way as training data
    new_data_processed = preprocess_data_for_catboost(new_data, categorical_cols, missing_placeholder)

    # Make prediction
    probabilities = model.predict_proba(new_data_processed)[0]

    recommendations = []
    all_recommended_plants = set()

    for i, label in enumerate(mlb_classes):
        prob = probabilities[i]
        if prob > threshold:
            # Ambil tanaman yang direkomendasikan untuk label ini
            plants = label_to_tanaman_dict.get(label, [])
            recommendations.append((label, prob, plants))
            all_recommended_plants.update(plants)

    # Urutkan rekomendasi berdasarkan confidence
    recommendations.sort(key=lambda x: x[1], reverse=True)

    return recommendations, list(all_recommended_plants)

# 6. Fungsi untuk menampilkan hasil dengan format yang lebih baik
def display_recommendations(recommendations, all_plants):
    """
    Menampilkan hasil rekomendasi dengan format yang lebih baik.
    """
    print("\n--- REKOMENDASI KONSERVASI ---")
    if recommendations:
        for i, (label, confidence, plants) in enumerate(recommendations, 1):
            print(f"{i}. {label}")
            print(f"   Tingkat Keyakinan: {confidence:.2%}")
            if plants:
                print(f"   Tanaman yang direkomendasikan: {', '.join(plants)}")
            else:
                print("   Tidak ada tanaman spesifik yang direkomendasikan")
            print()
    else:
        print("Tidak ada rekomendasi yang memenuhi threshold.")

    print("--- RINGKASAN TANAMAN ---")
    if all_plants:
        print("Semua tanaman yang direkomendasikan:")
        # Kelompokkan tanaman berdasarkan kategori atau urutkan alfabetis
        sorted_plants = sorted(all_plants)
        for i, plant in enumerate(sorted_plants, 1):
            print(f"{i}. {plant}")
    else:
        print("Tidak ada tanaman yang direkomendasikan.")

# Contoh penggunaan dengan missing values
print("\n--- TESTING WITH MISSING VALUES ---")
new_data = pd.DataFrame({
    'FungsiKaw': ['Areal Penggunaan Lain (APL)'],
    'chbulan': [None],  # Missing value
    'Lereng': ['Sangat Curam'],
    'Solumtnh': [None],  # Missing value
    'JnsLahan': ['Lahan Kering'],
    'LC2024': ['Kebun Campur'],
    'ErosiPot': ['Ringan'],
    'TBE': ['Sedang']
})

print("Original data with missing values:")
print(new_data)

recommendations, all_plants = predict_with_plant_recommendations(
    new_data, multi_label_model, mlb.classes_, label_to_tanaman,
    categorical_features_names, threshold=prediction_threshold
)

print(f"\n--- HASIL PREDIKSI DENGAN MISSING VALUES ---")
display_recommendations(recommendations, all_plants)

# 7. Test with different scenarios
print("\n--- TESTING DIFFERENT MISSING VALUE SCENARIOS ---")

# Scenario 1: All values present
test_data1 = pd.DataFrame({
    'FungsiKaw': ['Hutan Produksi'],
    'chbulan': ['Tinggi'],
    'Lereng': ['Curam'],
    'Solumtnh': ['Dalam'],
    'JnsLahan': ['Lahan Kering'],
    'LC2024': ['Hutan'],
    'ErosiPot': ['Sedang'],
    'TBE': ['Tinggi']
})

print("Scenario 1 - All values present:")
recs1, plants1 = predict_with_plant_recommendations(
    test_data1, multi_label_model, mlb.classes_, label_to_tanaman,
    categorical_features_names, threshold=prediction_threshold
)
print(f"Number of recommendations: {len(recs1)}")
print(f"Number of plants: {len(plants1)}")

# Scenario 2: Half missing
test_data2 = pd.DataFrame({
    'FungsiKaw': ['Hutan Lindung'],
    'chbulan': [None],
    'Lereng': ['Landai'],
    'Solumtnh': [None],
    'JnsLahan': [None],
    'LC2024': ['Pertanian'],
    'ErosiPot': [None],
    'TBE': ['Rendah']
})

print("\nScenario 2 - Half missing:")
recs2, plants2 = predict_with_plant_recommendations(
    test_data2, multi_label_model, mlb.classes_, label_to_tanaman,
    categorical_features_names, threshold=prediction_threshold
)
print(f"Number of recommendations: {len(recs2)}")
print(f"Number of plants: {len(plants2)}")

# 8. Save model
print("\n--- Saving Model ---")
model_filename = "catboost_multilabel_model_fixed.cbm"
multi_label_model.save_model(model_filename)
print(f"Model telah berhasil disimpan ke file: {model_filename}")

import pickle
import os

# 1. Save model CatBoost (.cbm)
model_filename = "catboost_multilabel_model.cbm"
multi_label_model.save_model(model_filename)

# 2. Save komponen pendukung
model_components = {
    'mlb': mlb,
    'label_to_tanaman': label_to_tanaman
    'categorical_features_names': categorical_features_names,
    'feature_names': list(X_processed.columns),
    'prediction_threshold': prediction_threshold
}

# Save ke pickle
components_filename = 'model_components.pkl'
with open(components_filename, 'wb') as f:
    pickle.dump(model_components, f)

print(f"Model saved to: {model_filename}")
print(f"Components saved to: {components_filename}")

# Cek file yang tersimpan
print(f"\n--- Files in current directory ---")
for file in [model_filename, components_filename]:
    if os.path.exists(file):
        size = os.path.getsize(file) / (1024*1024)  # MB
        print(f"{file} ({size:.2f} MB)")
    else:
        print(f"{file} not found")

from google.colab import files

try:
    files.download('catboost_multilabel_model.cbm')
    files.download('model_components.pkl')
    print("Files ready for download!")
except Exception as e:
    print(f"Download error: {e}")
    print("Files mungkin belum tersimpan dengan benar.")

